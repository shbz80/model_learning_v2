{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/opt/ros/melodic/lib/python2.7/dist-packages', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/home/hangyin/.local/lib/python3.6/site-packages', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/home/hangyin/.local/lib/python3.6/site-packages/IPython/extensions', '/home/hangyin/.ipython', '/home/hangyin/workspace/sandbox/', '/home/hangyin/workspace/sandbox/dyn_pred']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C, WhiteKernel as W\n",
    "from multidim_gp import MultidimGP\n",
    "from model_leraning_utils import UGP\n",
    "import time\n",
    "import pickle\n",
    "from blocks_sim import MassSlideWorld\n",
    "\n",
    "import sys\n",
    "if not '/home/hangyin/workspace/sandbox/' in sys.path:\n",
    "    sys.path.append('/home/hangyin/workspace/sandbox/')\n",
    "    sys.path.append('/home/hangyin/workspace/sandbox/dyn_pred')\n",
    "print(sys.path)\n",
    "import dyn_pred\n",
    "from dyn_pred.dynamics_predictor import DynamicsPredictor\n",
    "from dyn_pred.bnn_dyn.bnn_dyn import BNNDynamics\n",
    "from dyn_pred.gp_dyn.gp_dyn import GaussianProcessDynamics\n",
    "from dyn_pred.gp_dyn.manifold_gp.gpflow_nn_ker import NNFeaturedSE\n",
    "\n",
    "import gpflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#exp settings\n",
    "n_repeat = 1  #number of training instances for nn approaches\n",
    "horizons = [39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dX:2, dU:1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hangyin/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator StandardScaler from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hangyin/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator GaussianProcessRegressor from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hangyin/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator BayesianGaussianMixture from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hangyin/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator SVC from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "/home/hangyin/.local/lib/python3.6/site-packages/sklearn/base.py:251: UserWarning: Trying to unpickle estimator GridSearchCV from version 0.19.1 when using version 0.20.2. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nX # input state\\nL = np.array([.2, 1.])\\nXtrg =  18.\\nnoise = 3.\\ndX = np.array([Xtrg, 0.]).reshape(1,2) - X\\nU = np.dot(dX, L) # simple linear controller\\nU = U.reshape(X.shape[0],1)\\nif return_std:\\n    U_noise = np.full((U.shape), np.sqrt(noise))\\nreturn U, U_noise\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data and control things\n",
    "#logfile = \"./Results/blocks_exp_preprocessed_1.dat\"\n",
    "logfile = \"./Results/blocks_exp_preprocessed_data_rs_1.dat\"\n",
    "\n",
    "exp_data = pickle.load( open(logfile, \"rb\" ), encoding='latin1' )\n",
    "#print(exp_data.keys())\n",
    "exp_params = exp_data['exp_params']\n",
    "Xg = exp_data['Xg']  # sate ground truth\n",
    "Ug = exp_data['Ug']  # action ground truth\n",
    "dP = exp_params['dP'] # pos dim\n",
    "dV = exp_params['dV'] # vel dim\n",
    "dU = exp_params['dU'] # act dim\n",
    "dX = dP+dV # state dim\n",
    "T = exp_params['T'] - 1 # total time steps\n",
    "dt = exp_params['dt'] # sampling time\n",
    "n_train = exp_data['n_train'] # number or trials in training data\n",
    "n_test = exp_data['n_test'] # number or trials in testing data\n",
    "\n",
    "XU_t_train = exp_data['XU_t_train'] # shape: n_train*T, dXU, state-action, sequential data\n",
    "XUs_t_train = exp_data['XUs_t_train'] # shape: n_train, T, dXU, state-action, sequential data\n",
    "X_t1_train = exp_data['X_t1_train'] # shape: n_train*T, dX, next state, sequential data\n",
    "X_t_train = exp_data['X_t_train'] # shape: n_train*T, dX, current state, sequential data\n",
    "X_t_std_weighted_train = exp_data['X_t_std_weighted_train'] # same as X_t_train but standardized\n",
    "X_t1_std_weighted_train = exp_data['X_t1_std_weighted_train'] # same as X_t1_train but standardized\n",
    "X_t_test = exp_data['X_t_test']\n",
    "Xs_t_train = XUs_t_train[:, :, :dX]\n",
    "X_scaler = exp_data['X_scaler']\n",
    "XU_t_std_train = exp_data['XU_t_std_train']\n",
    "XU_scaler = exp_data['XU_scaler']\n",
    "\n",
    "ugp_params = {\n",
    "    'alpha': 1.,\n",
    "    'kappa': 2.,\n",
    "    'beta': 0.,\n",
    "}\n",
    "\n",
    "print('dX:{0}, dU:{1}'.format(dX, dU))\n",
    "\n",
    "policy_params = exp_params['policy'] # TODO: the block_sim code assumes only 'm1' mode for control\n",
    "expl_noise = policy_params['m1']['noise_pol']\n",
    "H = T  # prediction horizon\n",
    "\n",
    "gpr_params = {\n",
    "            # 'alpha': 1e-2,  # alpha=0 when using white kernal\n",
    "            'alpha': 0.,  # alpha=0 when using white kernal\n",
    "            'kernel': C(1.0, (1e-2, 1e2)) * RBF(np.ones(dX + dU), (1e-2, 1e2)) + W(noise_level=1.,\n",
    "                                                                                   noise_level_bounds=(1e-4, 1e1)),\n",
    "            # 'kernel': C(1.0, (1e-1, 1e1)) * RBF(np.ones(dX + dU), (1e-1, 1e1)),\n",
    "            'n_restarts_optimizer': 10,\n",
    "            'normalize_y': False,  # is not supported in the propogation function\n",
    "        }\n",
    "\n",
    "gpr_params_list = []\n",
    "gpr_params_list.append(gpr_params)\n",
    "gpr_params_list.append(gpr_params)\n",
    "# gpr_params_list.append(gpr_params_p_d)\n",
    "# gpr_params_list.append(gpr_params_v_d)\n",
    "\n",
    "\n",
    "#and world\n",
    "# global gp long-term prediction\n",
    "massSlideParams = exp_params['massSlide']\n",
    "# policy_params = exp_params['policy']\n",
    "massSlideWorld = MassSlideWorld(**massSlideParams)\n",
    "massSlideWorld.set_policy(policy_params)\n",
    "massSlideWorld.reset()\n",
    "mode = 'm1'  # only one mode for control no matter what X\n",
    "\n",
    "ugp_global_dyn = UGP(dX + dU, **ugp_params) # initialize unscented transform for dynamics\n",
    "ugp_global_pol = UGP(dX, **ugp_params) # initialize unscented transform for policy\n",
    "\n",
    "x_mu_t = exp_data['X0_mu']  # mean of initial state distr\n",
    "x_var_t = np.diag(exp_data['X0_var'])\n",
    "x_var_t[1,1] = 1e-6   # setting small variance for initial vel    # TODO: cholesky failing for zero v0 variance\n",
    "\n",
    "\n",
    "############ Policy assumptions #######\n",
    "'''\n",
    "X # input state\n",
    "L = np.array([.2, 1.])\n",
    "Xtrg =  18.\n",
    "noise = 3.\n",
    "dX = np.array([Xtrg, 0.]).reshape(1,2) - X\n",
    "U = np.dot(dX, L) # simple linear controller\n",
    "U = U.reshape(X.shape[0],1)\n",
    "if return_std:\n",
    "    U_noise = np.full((U.shape), np.sqrt(noise))\n",
    "return U, U_noise\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 0-th repetition...\n",
      "Created an ensemble of 5 neural networks with variance predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 100/100 [00:00<00:00, 112.83epoch(s)/s, Training loss(es)=[0.02532835 0.01886144 0.02449165 0.01352611 0.01993136]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bnn_res = dict()\n",
    "for h in horizons:\n",
    "    bnn_res['horizon_{0}'.format(h)] = []\n",
    "    for r in range(n_repeat):\n",
    "        print('Training for the {0}-th repetition...'.format(r))\n",
    "        curr_res = dict()\n",
    "        \n",
    "        #for BNN\n",
    "        tf.reset_default_graph()\n",
    "        model = DynamicsPredictor(model=BNNDynamics(layers=[3, 5, 2], n_nets=5, name='bnn2d'))  #input 3d , output 2d\n",
    "\n",
    "        model.train(XU_t_train, X_t1_train)\n",
    "        \n",
    "        #prediction\n",
    "        x_mu_t = exp_data['X0_mu']  # mean of initial state distr\n",
    "        x_var_t = np.diag(exp_data['X0_var'])\n",
    "        x_var_t[1,1] = 1e-6   # setting small variance for initial vel    # TODO: cholesky failing for zero v0 variance\n",
    "\n",
    "        X_mu_pred = []  # list for collecting state mean\n",
    "        X_var_pred = [] # list for collecting state var\n",
    "        #for our baseline models to predict\n",
    "        for t in range(h):\n",
    "            # UT method on stochastic policy, policy is deterministic controller plus exploration noise\n",
    "            u_mu_t, u_var_t, _, _, xu_cov = ugp_global_pol.get_posterior_pol(massSlideWorld, x_mu_t, x_var_t)\n",
    "            # form joint state action distribution\n",
    "            xu_mu_t = np.append(x_mu_t, u_mu_t)\n",
    "            # xu_var_t = np.block([[x_var_t, np.zeros((dX,dU))],\n",
    "            #                     [np.zeros((dU,dX)), u_var_t]])\n",
    "            # TODO: xu_cov may not be correct so disable below and enable above later\n",
    "            xu_var_t = np.block([[x_var_t, xu_cov],\n",
    "                                 [xu_cov.T, u_var_t]])\n",
    "            X_mu_pred.append(x_mu_t)\n",
    "            X_var_pred.append(x_var_t)\n",
    "            # UT method for one step dynamics prediction\n",
    "            x_mu_t, x_var_t = model.predict(np.array([xu_mu_t]), np.array([xu_var_t]))\n",
    "            # unpack because our method takes a batch as input\n",
    "            x_mu_t = x_mu_t[0]\n",
    "            x_var_t = x_var_t[0]\n",
    "\n",
    "        #print(len(X_mu_pred), len(X_var_pred))\n",
    "        curr_res['pred_x_mu'] = X_mu_pred\n",
    "        curr_res['pred_x_var'] = X_var_pred\n",
    "        \n",
    "        #loglikelihood score\n",
    "        XUs_t_test = exp_data['XUs_t_test']\n",
    "        assert(XUs_t_test.shape[0]==n_test)\n",
    "        X_test_log_ll = np.zeros((h, n_test))\n",
    "        for t in range(h):      # one data point less than in XU_test\n",
    "            for i in range(n_test):\n",
    "                XU_test = XUs_t_test[i]\n",
    "                x_t = XU_test[t, :dX]\n",
    "                x_mu_t = X_mu_pred[t]\n",
    "                x_var_t = X_var_pred[t]\n",
    "                X_test_log_ll[t, i] = sp.stats.multivariate_normal.logpdf(x_t, x_mu_t, x_var_t)\n",
    "        \n",
    "        curr_res['ll_score'] = X_test_log_ll\n",
    "        \n",
    "        bnn_res['horizon_{0}'.format(h)].append(curr_res)\n",
    "        \n",
    "        del model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('bnn_res', bnn_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 0-th repetition...\n",
      "Created an ensemble of 5 neural networks with variance predictions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Network training: 100%|██████████| 100/100 [00:00<00:00, 94.25epoch(s)/s, Training loss(es)=[0.01928245 0.01958094 0.02187146 0.03781505 0.01816209]]\n"
     ]
    }
   ],
   "source": [
    "#for multimodal output of BNN\n",
    "#here we adopt a simple propagation rule: treat each gaussian output in the ensemble as a local model by itself and maintain the ensemble all through the trajectory\n",
    "bnn_multm_res = dict()\n",
    "n_nets = 5\n",
    "\n",
    "for h in horizons:\n",
    "    bnn_multm_res['horizon_{0}'.format(h)] = []\n",
    "    for r in range(n_repeat):\n",
    "        print('Training for the {0}-th repetition...'.format(r))\n",
    "        curr_res = dict()\n",
    "        \n",
    "        #for BNN\n",
    "        tf.reset_default_graph()\n",
    "        model = DynamicsPredictor(model=BNNDynamics(layers=[3, 5, 2], n_nets=n_nets, name='bnn2d'))  #input 3d , output 2d\n",
    "\n",
    "        model.train(XU_t_train, X_t1_train)\n",
    "        \n",
    "        #prediction\n",
    "        #we need a predictor indexing the i-th nn in the ensemble\n",
    "        class multimodal_predict(object):\n",
    "            def __init__(self, bnn_model, index):\n",
    "                self.bnn_model = bnn_model\n",
    "                self.index = index\n",
    "            \n",
    "            def predict(self, inputs, return_std=True):\n",
    "                means, variances = self.bnn_model.predict(inputs, factored=True)\n",
    "                return means[self.index], np.sqrt(variances[self.index])  #return std instead, because get_posterior needs this\n",
    "                \n",
    "        #prepare predictor for each model in the ensemble\n",
    "        predictors = [multimodal_predict(model.model.bnn_model, i_model) for i_model in range(n_nets)]\n",
    "       \n",
    "        x_mu_t = exp_data['X0_mu']  # mean of initial state distr\n",
    "        x_var_t = np.diag(exp_data['X0_var'])\n",
    "        x_var_t[1,1] = 1e-6   # setting small variance for initial vel    # TODO: cholesky failing for zero v0 variance\n",
    "        \n",
    "        x_mu_t = np.array([x_mu_t.copy() for i in range(n_nets)])\n",
    "        x_var_t = np.array([x_var_t.copy() for i in range(n_nets)])\n",
    "        \n",
    "        X_mu_pred = []  # list for collecting state mean\n",
    "        X_var_pred = [] # list for collecting state var\n",
    "        #for our baseline models to predict\n",
    "        for t in range(h):\n",
    "            X_mu_pred.append(x_mu_t.copy())\n",
    "            X_var_pred.append(x_var_t.copy())\n",
    "            for i_model in range(n_nets):\n",
    "                # UT method on stochastic policy, policy is deterministic controller plus exploration noise\n",
    "                u_mu_t, u_var_t, _, _, xu_cov = ugp_global_pol.get_posterior_pol(massSlideWorld, x_mu_t[i_model], x_var_t[i_model])\n",
    "                # form joint state action distribution\n",
    "                xu_mu_t = np.append(x_mu_t[i_model], u_mu_t)\n",
    "                # xu_var_t = np.block([[x_var_t, np.zeros((dX,dU))],\n",
    "                #                     [np.zeros((dU,dX)), u_var_t]])\n",
    "                # TODO: xu_cov may not be correct so disable below and enable above later\n",
    "                xu_var_t = np.block([[x_var_t[i_model], xu_cov],\n",
    "                                     [xu_cov.T, u_var_t]])\n",
    "\n",
    "                # UT method for one step dynamics prediction\n",
    "                # x_mu_t, x_var_t = model.predict(np.array([xu_mu_t]), np.array([xu_var_t]))\n",
    "                \n",
    "                x_mu_t_new, x_var_t_new, _, _, _ = ugp_global_dyn.get_posterior(predictors[i_model], xu_mu_t, xu_var_t)\n",
    "                \n",
    "                # unpack because our method takes a batch as input\n",
    "                x_mu_t[i_model] = x_mu_t_new\n",
    "                x_var_t[i_model] = x_var_t_new\n",
    "\n",
    "        #print(len(X_mu_pred), len(X_var_pred))\n",
    "        curr_res['pred_x_mu'] = X_mu_pred\n",
    "        curr_res['pred_x_var'] = X_var_pred\n",
    "        \n",
    "        #loglikelihood score\n",
    "        XUs_t_test = exp_data['XUs_t_test']\n",
    "        assert(XUs_t_test.shape[0]==n_test)\n",
    "        X_test_log_ll = np.zeros((h, n_test))\n",
    "        for t in range(h):      # one data point less than in XU_test\n",
    "            for i in range(n_test):\n",
    "                XU_test = XUs_t_test[i]\n",
    "                x_t = XU_test[t, :dX]\n",
    "                x_mu_t = X_mu_pred[t]\n",
    "                x_var_t = X_var_pred[t]\n",
    "                #taking the mean of log of mean pdf\n",
    "                X_test_log_ll[t, i] = np.log(np.mean([sp.stats.multivariate_normal.pdf(x_t, x_mu_t[j], x_var_t[j]) for j in range(n_nets)]))\n",
    "        \n",
    "        curr_res['ll_score'] = X_test_log_ll\n",
    "        \n",
    "        bnn_multm_res['horizon_{0}'.format(h)].append(curr_res)\n",
    "        \n",
    "        del model\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('bnn_multm_res', bnn_multm_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gpflow.logdensities:Shape of x must be 2D at computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for the 0-th repetition...\n",
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: -733.438665\n",
      "  Number of iterations: 188\n",
      "  Number of functions evaluations: 328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Optimization terminated with:\n",
      "  Message: b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH'\n",
      "  Objective function value: -733.438665\n",
      "  Number of iterations: 188\n",
      "  Number of functions evaluations: 328\n"
     ]
    }
   ],
   "source": [
    "mgp_res = dict()\n",
    "for h in horizons:\n",
    "    mgp_res['horizon_{0}'.format(h)] = []\n",
    "    for r in range(n_repeat):\n",
    "        print('Training for the {0}-th repetition...'.format(r))\n",
    "        curr_res = dict()\n",
    "        \n",
    "        #for mGP\n",
    "        #tf.reset_default_graph()\n",
    "        model = DynamicsPredictor(model=GaussianProcessDynamics(kern=NNFeaturedSE(3, [3, 3, 2])))\n",
    "        model.train(XU_t_train, X_t1_train)\n",
    "        \n",
    "        #prediction\n",
    "        x_mu_t = exp_data['X0_mu']  # mean of initial state distr\n",
    "        x_var_t = np.diag(exp_data['X0_var'])\n",
    "        x_var_t[1,1] = 1e-6   # setting small variance for initial vel    # TODO: cholesky failing for zero v0 variance\n",
    "\n",
    "        X_mu_pred = []  # list for collecting state mean\n",
    "        X_var_pred = [] # list for collecting state var\n",
    "        #for our baseline models to predict\n",
    "        for t in range(h):\n",
    "            # UT method on stochastic policy, policy is deterministic controller plus exploration noise\n",
    "            u_mu_t, u_var_t, _, _, xu_cov = ugp_global_pol.get_posterior_pol(massSlideWorld, x_mu_t, x_var_t)\n",
    "            # form joint state action distribution\n",
    "            xu_mu_t = np.append(x_mu_t, u_mu_t)\n",
    "            # xu_var_t = np.block([[x_var_t, np.zeros((dX,dU))],\n",
    "            #                     [np.zeros((dU,dX)), u_var_t]])\n",
    "            # TODO: xu_cov may not be correct so disable below and enable above later\n",
    "            xu_var_t = np.block([[x_var_t, xu_cov],\n",
    "                                 [xu_cov.T, u_var_t]])\n",
    "            X_mu_pred.append(x_mu_t)\n",
    "            X_var_pred.append(x_var_t)\n",
    "            # UT method for one step dynamics prediction\n",
    "            x_mu_t, x_var_t = model.predict(np.array([xu_mu_t]), np.array([xu_var_t]))\n",
    "            # unpack because our method takes a batch as input\n",
    "            x_mu_t = x_mu_t[0]\n",
    "            x_var_t = x_var_t[0]\n",
    "\n",
    "        #print(len(X_mu_pred), len(X_var_pred))\n",
    "        curr_res['pred_x_mu'] = X_mu_pred\n",
    "        curr_res['pred_x_var'] = X_var_pred\n",
    "        \n",
    "        #loglikelihood score\n",
    "        XUs_t_test = exp_data['XUs_t_test']\n",
    "        assert(XUs_t_test.shape[0]==n_test)\n",
    "        X_test_log_ll = np.zeros((h, n_test))\n",
    "        for t in range(h):      # one data point less than in XU_test\n",
    "            for i in range(n_test):\n",
    "                XU_test = XUs_t_test[i]\n",
    "                x_t = XU_test[t, :dX]\n",
    "                x_mu_t = X_mu_pred[t]\n",
    "                x_var_t = X_var_pred[t]\n",
    "                X_test_log_ll[t, i] = sp.stats.multivariate_normal.logpdf(x_t, x_mu_t, x_var_t)\n",
    "        \n",
    "        curr_res['ll_score'] = X_test_log_ll\n",
    "        \n",
    "        mgp_res['horizon_{0}'.format(h)].append(curr_res)\n",
    "        \n",
    "        del model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('mgp_res', mgp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualize results\n",
    "bnn_res = np.load('bnn_res.npy').item()['horizon_39']\n",
    "bnn_multm_res = np.load('bnn_multm_res.npy').item()['horizon_39']\n",
    "mgp_res = np.load('mgp_res.npy').item()['horizon_39']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.680977105462901, -1.2030185726740896, -2.6898033171232765, -3.375594764625171, -3.7787940711238197] [5.058004020071688, 4.431635858213129, 3.639289622621094, 3.4155539093013707, 3.276533139231654]\n",
      "[1.4520647057357121, 0.1337909372034716, -0.6812817436733789, -1.0044993512753992, -1.5607965962747472] [4.032592948702285, 3.3509086372763597, 2.4882413397809127, 2.0931346821918044, 2.056002033592083]\n",
      "[4.384485597693387, 3.1261418587030687, 1.6811852595184336, 1.073296794762321, 0.6259694826559493] [2.617223023352371, 2.4372680908064073, 2.2159484423991778, 1.9869347055782878, 1.9072260327924773]\n"
     ]
    }
   ],
   "source": [
    "#lets see scores\n",
    "eval_horizons = [5, 9, 19, 29, 39]\n",
    "\n",
    "approaches = ['mGP', 'BNN', 'BNN-MM']\n",
    "\n",
    "mgp_score_avg = []\n",
    "mgp_score_std = []\n",
    "bnn_score_avg = []\n",
    "bnn_score_std = []\n",
    "bnn_mm_score_avg = []\n",
    "bnn_mm_score_std = []\n",
    "\n",
    "for h in eval_horizons:\n",
    "    mgp_score = []\n",
    "    bnn_score = []\n",
    "    for trial in range(1):\n",
    "        #only look at the one repetition for the consistency with Shahbaz's criterion\n",
    "        #bnn_score.append(np.mean(bnn_res[trial]['ll_score'][:h]))\n",
    "        #mgp_score.append(np.mean(mgp_res[trial]['ll_score'][:h]))\n",
    "        bnn_score = bnn_res[trial]['ll_score'][:h]\n",
    "        bnn_mm_score = bnn_multm_res[trial]['ll_score'][:h]\n",
    "        mgp_score = mgp_res[trial]['ll_score'][:h]\n",
    "    mgp_score_avg.append(np.mean(mgp_score))\n",
    "    mgp_score_std.append(np.std(mgp_score))\n",
    "    bnn_score_avg.append(np.mean(bnn_score))\n",
    "    bnn_score_std.append(np.std(bnn_score))\n",
    "    bnn_mm_score_avg.append(np.mean(bnn_mm_score))\n",
    "    bnn_mm_score_std.append(np.std(bnn_mm_score))\n",
    "\n",
    "print(mgp_score_avg, mgp_score_std)\n",
    "print(bnn_score_avg, bnn_score_std)\n",
    "print(bnn_mm_score_avg, bnn_mm_score_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%matplotlib auto\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "mgp_plt = ax.bar(eval_horizons, mgp_score_avg, yerr=mgp_score_std)\n",
    "bnn_plt = ax.bar(np.array(eval_horizons)-0.75, bnn_score_avg, yerr=bnn_score_std)\n",
    "bnn_mm_plt = ax.bar(np.array(eval_horizons)-1.5, bnn_mm_score_avg, yerr=bnn_mm_score_std)\n",
    "\n",
    "ax.set_xlabel('Prediction Horizon', fontsize=16)\n",
    "ax.set_ylabel('Log-likelihood Score', fontsize=16)\n",
    "\n",
    "ax.legend((mgp_plt, bnn_plt, bnn_mm_plt), approaches, fontsize=16)\n",
    "ax.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
